{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PDxuMGVpf3mF",
        "a0wG6VIS_Fbx",
        "OLy-m7UEoHTd",
        "UynZO14iMPBf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ],
      "metadata": {
        "id": "IsLRbiftmGU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "BsEWWyamc8ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jedi --quiet\n",
        "!pip install snntorch --quiet\n",
        "!pip install brevitas --quiet"
      ],
      "metadata": {
        "id": "Xil35Lt5gGc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "from snntorch import spikegen\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch.functional import quant\n",
        "\n",
        "import brevitas.nn as qnn\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms,datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "JKo1-vkjc769"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nkYcnjA-iOj"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/My Drive/project_aug/v4'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzPwd3GRcmcD",
        "outputId": "c7f34dcb-183c-477f-970f-e03cd0cb7c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.Resize((14,14)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "test_data = datasets.FashionMNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "num_workers=0\n",
        "batch_size=50\n",
        "test_loader=torch.utils.data.DataLoader(test_data,batch_size=batch_size,num_workers=num_workers)\n",
        "\n",
        "print(f\"Test data size : {test_loader.dataset.__len__()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_RqUkEwcvH7",
        "outputId": "8a287775-def7-4085-fcc8-12307327ee1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data size : 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "PDxuMGVpf3mF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0siXDqyDAvTU"
      },
      "outputs": [],
      "source": [
        "# neuron and simulation parameters\n",
        "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
        "beta = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd7wIS9yArKb"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernal_size, padding, use_pool=False):\n",
        "    super(ConvNet,self).__init__()\n",
        "    # self.conv=nn.Conv2d(in_channels,out_channels,kernal_size,padding=padding)\n",
        "    self.conv = qnn.QuantConv2d(in_channels, out_channels, kernal_size, padding=padding, bias=False, weight_bit_width=8)\n",
        "    self.use_pool = use_pool\n",
        "    self.pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    self.activation= nn.ReLU()\n",
        "\n",
        "  def forward(self,data):\n",
        "    if self.use_pool:\n",
        "      return self.activation(self.pool(self.conv(data)));\n",
        "    else:\n",
        "      return self.activation(self.conv(data));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUSR6JaYAtpu"
      },
      "outputs": [],
      "source": [
        "class SnnNet(nn.Module):\n",
        "  def __init__(self,num_steps,in_channels=8,out_channels=16, use_pool=False):\n",
        "    super(SnnNet,self).__init__()\n",
        "    self.use_pool = use_pool\n",
        "    self.num_steps = num_steps\n",
        "\n",
        "    qlif = quant.state_quant(num_bits=8, uniform=False, thr_centered=True)\n",
        "\n",
        "    # self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1,stride=1)\n",
        "    self.conv = qnn.QuantConv2d(in_channels, out_channels, kernel_size=3,padding=0,stride=1, bias=False, weight_bit_width=8)\n",
        "    # self.lif1 = snn.Leaky(beta=beta, state_quant=qlif)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    self.activation = snn.Leaky(beta=beta, spike_grad=spike_grad, state_quant=qlif, reset_mechanism = \"zero\")\n",
        "\n",
        "  def forward(self,data):\n",
        "    self.activation.reset_mem()\n",
        "    out = []\n",
        "    mems_out = []\n",
        "    for step in range(self.num_steps):\n",
        "      output = self.conv(data[step])\n",
        "      spike_out, mem_out = self.activation(output)\n",
        "\n",
        "      if self.use_pool:\n",
        "        spike_out = self.pool(spike_out);\n",
        "        mem_out = self.pool(mem_out);\n",
        "\n",
        "      out.append(spike_out)\n",
        "      mems_out.append(mem_out)\n",
        "\n",
        "    return torch.stack(out,dim=0), torch.stack(mems_out,dim=0)\n",
        "    # return torch.sum(snn_out, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B93al9zhBCHD"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,num_steps=0, use_spike=False):\n",
        "    super(Net,self).__init__()\n",
        "    self.use_spike = use_spike\n",
        "    self.num_steps = num_steps\n",
        "    self.mainArch = self.createNet()\n",
        "    self.fcs = self.createfcs()\n",
        "    self.layer1_output = None\n",
        "    self.spike_encoded_input = None\n",
        "    self.layer2_output_spk = None\n",
        "    self.layer2_output_mem = None\n",
        "    self.layer2_output = None\n",
        "    self.spike_output = None\n",
        "\n",
        "  def createNet(self):\n",
        "    layers = [ConvNet(1,8,5,0, True)]\n",
        "    if self.use_spike:\n",
        "      layers.append(SnnNet(num_steps=self.num_steps,use_pool=False))\n",
        "    else:\n",
        "      layers.append(ConvNet(8,16,3,0,use_pool=False))\n",
        "\n",
        "    layers.append(ConvNet(16,16,1,0, False))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def createfcs(self):\n",
        "    return nn.Sequential(\n",
        "        nn.Dropout(0.2),\n",
        "        qnn.QuantLinear(3*3*16,512, bias=True, weight_bit_width=8),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        qnn.QuantLinear(512,256, bias=True, weight_bit_width=8),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        qnn.QuantLinear(256,10, bias=True, weight_bit_width=8)\n",
        "    )\n",
        "\n",
        "  def forward(self, data):\n",
        "    x= data\n",
        "    self.layer1_output = self.mainArch[0](x)\n",
        "    if self.use_spike:   # Spike encoding on the output of the first layer\n",
        "      self.spike_encoded_input = spikegen.rate(self.layer1_output, self.num_steps)\n",
        "      self.layer2_output, self.layer2_output_mem = self.mainArch[1](self.spike_encoded_input)\n",
        "      self.spike_output = self.layer2_output\n",
        "      self.layer2_output = torch.sum(self.layer2_output, dim=0)\n",
        "    else:\n",
        "      self.layer2_output = self.mainArch[1](self.layer1_output)\n",
        "    x = self.mainArch[2](self.layer2_output)\n",
        "    x = x.view(-1, 3 * 3 * 16)\n",
        "    return self.fcs(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model"
      ],
      "metadata": {
        "id": "a0wG6VIS_Fbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scnn_model = Net(num_steps=3,use_spike=True)"
      ],
      "metadata": {
        "id": "jKEPGhnJfvIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scnn_model_path = base_path + '/model/Net_scnn_frz2_quant8b_model.pth'\n",
        "scnn_state_dict = torch.load(scnn_model_path, map_location=torch.device('cpu'))\n",
        "scnn_model.load_state_dict(scnn_state_dict, False)\n",
        "scnn_model.eval()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llN9FeAt--hD",
        "outputId": "d348b8ee-ed52-4727-c59b-2d49016e4919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pick an Image\n",
        "\n"
      ],
      "metadata": {
        "id": "yTzpNNH0E2-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "    Get a random image by its label from the test loader.\n",
        "\n",
        "    Parameters:\n",
        "    - loader (DataLoader): The DataLoader from which to fetch the image.\n",
        "    - label (int): The label of the image to fetch.\n",
        "\n",
        "    Returns:\n",
        "    - image (Tensor): The image tensor.\n",
        "```"
      ],
      "metadata": {
        "id": "pmXEloVkJDjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_class={\n",
        "    0:\"T-shirt/top\",\n",
        "    1:\"Trouser\",\n",
        "    2:\"Pullover\",\n",
        "    3:\"Dress\",\n",
        "    4:\"Coat\",\n",
        "    5:\"Sandal\",\n",
        "    6:\"Shirt\",\n",
        "    7:\"Sneaker\",\n",
        "    8:\"Bag\",\n",
        "    9:\"Ankle boot\"\n",
        "}\n",
        "\n",
        "def get_random_image_by_label(loader, label):\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Collect all images with the specified label\n",
        "    for batch_images, batch_labels in loader:\n",
        "        for img, lbl in zip(batch_images, batch_labels):\n",
        "            if lbl == label:\n",
        "                images.append(img)\n",
        "                labels.append(lbl)\n",
        "\n",
        "    if not images:\n",
        "        raise ValueError(f\"No images found with label {label}\")\n",
        "\n",
        "    # Choose a random image\n",
        "    idx = random.randint(0, len(images) - 1)\n",
        "    selected_image = images[idx]\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(selected_image.squeeze(), cmap=\"gray\")\n",
        "    plt.title(f\"Label: {label}, {fashion_class[label]}\")\n",
        "    plt.show()\n",
        "\n",
        "    return selected_image, idx\n"
      ],
      "metadata": {
        "id": "CNkoH3UHE2sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference pass\n",
        "\n",
        "Might not be able to extract INT weights here. so extract fp32 non-qunatized weights"
      ],
      "metadata": {
        "id": "x0A8-rm3GQqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_image, idx = get_random_image_by_label(test_loader, 2)\n",
        "\n",
        "scnn_model.eval()\n",
        "with torch.no_grad():\n",
        "  spk_rec  = scnn_model(random_image)       # Pass the random image to the model\n",
        "\n",
        "predicted = spk_rec[-1].max(0, keepdim=True)[1]\n",
        "\n",
        "\n",
        "\n",
        "layer1_output = scnn_model.layer1_output\n",
        "spike_encoded_input = scnn_model.spike_encoded_input\n",
        "spike_output = scnn_model.spike_output\n",
        "spike_encoded_input.shape\n",
        "\n",
        "np.save(base_path + '/input_output/in_spk_' + str(idx)+ '.npy', random_image.numpy())\n",
        "# np.save(base_path + '/input_output/in_spk.npy', spike_encoded_output.numpy())\n",
        "# np.save(base_path + '/input_output/out_spk.npy', layer2_output.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gwdWMrtWGTQp",
        "outputId": "d53a79cc-c6c6-469f-8b82-f59a1a945883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Predicted class: {predicted}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW1G3_J7q8xt",
        "outputId": "e10d845a-1ef0-4b6d-d691-639d50b11369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ],
      "metadata": {
        "id": "Qz0qqkD1mJu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights\n",
        "Non_quantized_float, quantized_float, quantized_int weights"
      ],
      "metadata": {
        "id": "OLy-m7UEoHTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in scnn_model.named_modules():\n",
        "    if isinstance(module, qnn.QuantConv2d) and 'mainArch.1.conv' in name:\n",
        "        print(name)\n",
        "        fp32_weights = module.weight.detach().cpu().numpy()     # Non qunatized weight\n",
        "        break\n",
        "\n",
        "quant_weight_float = np.load(base_path + '/model_weights/quant_weight_float.npy')\n",
        "quant_weight_int = np.load(base_path + '/model_weights/quant_weight_int.npy')\n",
        "\n",
        "# print(fp32_weights.shape)\n",
        "# print(quant_weight_float.shape)\n",
        "print(quant_weight_int.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMq8WEyXmMBk",
        "outputId": "53780294-ecac-41a0-f7d0-c329e748caa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mainArch.1.conv\n",
            "(16, 8, 3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "UynZO14iMPBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_output_for_vhdl(output, file_path):\n",
        "    with open(file_path + '.txt', 'w') as f:\n",
        "        total_elements = output.numel()\n",
        "        zero_elements = torch.sum(output == 0).item()\n",
        "        sparsity = (zero_elements / total_elements) *100\n",
        "        f.write(f\"Sparsity: {sparsity}\\n\")\n",
        "\n",
        "        output_np = output.detach().cpu().numpy()\n",
        "        num_channels = output_np.shape[0]\n",
        "\n",
        "        for channel_idx in range(num_channels):\n",
        "            channel_data = output_np[channel_idx, :, :]\n",
        "            f.write(f\"Channel {channel_idx}:\\n\")\n",
        "            np.savetxt(f, channel_data, fmt='%.6f')\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "        # Save output as numpy file\n",
        "        np.save(file_path + '.npy', output_np)"
      ],
      "metadata": {
        "id": "E4PYzMGvvqDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LIF"
      ],
      "metadata": {
        "id": "B3Y4tNDG0hro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = base_path + '/input_output/'\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "for step in range(spike_encoded_input.shape[0]):\n",
        "    in_spk_file_path = os.path.join(output_path, 'in_spk_8b'+ str(step))\n",
        "    save_output_for_vhdl(spike_encoded_input[step], in_spk_file_path)\n",
        "\n",
        "for step in range(spike_output.shape[0]):\n",
        "  out_spk_file_path = os.path.join(output_path, 'out_spk_8b'+ str(step))\n",
        "  save_output_for_vhdl(spike_output[step], out_spk_file_path)"
      ],
      "metadata": {
        "id": "Mfj-31vSod0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_lif_neurons(input_data, weights, threshold= 1.0, beta=1, reset_value=0.0):\n",
        "    # Assuming input_data shape is (time, channels, height, width)\n",
        "    time_steps = input_data.shape[0]\n",
        "\n",
        "    # Determine output shape after convolution\n",
        "    output_shape = (time_steps, weights.shape[0],  # (time, output_channels, height, width)\n",
        "                    input_data.shape[2] - weights.shape[2] + 1,\n",
        "                    input_data.shape[3] - weights.shape[3] + 1)\n",
        "\n",
        "    # if isinstance(thresholds, (float, int)):\n",
        "    #     thresholds = np.full(time_steps, thresholds)  # If a single threshold is given, replicate it across all timesteps\n",
        "\n",
        "    # Initialize output spikes\n",
        "    output_spikes = np.zeros(output_shape)  # Shape: (time, output_channels, height, width)\n",
        "\n",
        "\n",
        "    # Initialize membrane potential for this timestep\n",
        "    membrane_potential = np.zeros((time_steps, weights.shape[0], output_shape[2], output_shape[3]))  # Shape: (output_channels, height, width)\n",
        "\n",
        "    # Perform convolution for the current timestep\n",
        "    for out_channel in range(output_shape[1]):\n",
        "        for i in range(output_shape[2]):\n",
        "            for j in range(output_shape[3]):\n",
        "              for t in range(time_steps):\n",
        "                # Calculate convolution output at this stride\n",
        "                conv_output = np.sum(input_data[t, :, i:i+weights.shape[2], j:j+weights.shape[3]] * weights[out_channel])\n",
        "\n",
        "                # Update membrane potential with leaky integration\n",
        "                if t == 0:\n",
        "                  membrane_potential[t, out_channel, i, j] = beta * membrane_potential[t, out_channel, i, j] + conv_output\n",
        "                else:\n",
        "                  membrane_potential[t, out_channel, i, j] = beta * membrane_potential[t-1, out_channel, i, j] + conv_output\n",
        "\n",
        "                # Generate spike if membrane potential exceeds threshold\n",
        "                if membrane_potential[t, out_channel, i, j] >= threshold:\n",
        "                    output_spikes[t, out_channel, i, j] = 1\n",
        "                    # Reset membrane potential where spike occurred\n",
        "                    # membrane_potential[t,out_channel, i, j] = membrane_potential[t,out_channel, i, j]-threshold\n",
        "                    membrane_potential[t,out_channel, i, j] = reset_value\n",
        "\n",
        "    return output_spikes, membrane_potential\n"
      ],
      "metadata": {
        "id": "QshSczQwEcrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "dvBvS1ln0kzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data = spike_encoded_input.numpy()\n",
        "# output_spikes, membrane_potential = apply_lif_neurons(input_data, fp32_weights, threshold= 1.0)\n",
        "\n",
        "# input_data = spike_encoded_input.numpy()\n",
        "# output_spikes, membrane_potential = apply_lif_neurons(input_data, quant_weight_float, threshold= 1.0)\n",
        "\n",
        "input_data = spike_encoded_input.numpy()\n",
        "# output_spikes, membrane_potential = apply_lif_neurons(input_data, quant_weight_int, threshold= 101.0101)\n",
        "output_spikes, membrane_potential = apply_lif_neurons(input_data, quant_weight_int, threshold= 101)"
      ],
      "metadata": {
        "id": "twTM5Yl30_cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_spikes[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC6AQmVOxtk5",
        "outputId": "c868a762-ac1b-4d36-cecc-b182faafcf50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [1. 0. 0.]\n",
            "  [0. 0. 1.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 1. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 1.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0.]\n",
            "  [1. 1. 0.]\n",
            "  [0. 1. 1.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [1. 0. 0.]\n",
            "  [1. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 1.]\n",
            "  [1. 0. 1.]\n",
            "  [1. 0. 1.]]\n",
            "\n",
            " [[1. 1. 0.]\n",
            "  [1. 1. 0.]\n",
            "  [1. 1. 0.]]\n",
            "\n",
            " [[0. 0. 1.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_results(row, col, channel):\n",
        "  conv_output = input_data[0, :, row:row+quant_weight_int.shape[2], col:col+quant_weight_int.shape[3]] * quant_weight_int[channel]\n",
        "  print(np.sum(conv_output))\n",
        "  conv_output = input_data[1, :, row:row+quant_weight_int.shape[2], col:col+quant_weight_int.shape[3]] * quant_weight_int[channel]\n",
        "  print(np.sum(conv_output))\n",
        "  conv_output = input_data[2, :, row:row+quant_weight_int.shape[2], col:col+quant_weight_int.shape[3]] * quant_weight_int[channel]\n",
        "  print(np.sum(conv_output))\n",
        "\n",
        "conv_results(1, 1, 14)\n",
        "\n",
        "# conv_output = input_data[1, :, 2:2+quant_weight_int.shape[2], 2:2+quant_weight_int.shape[3]] * quant_weight_int[0]\n",
        "# # print(conv_output)\n",
        "# print(np.sum(conv_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7B-P0wKJCdF",
        "outputId": "76255266-40a5-4e3e-d268-b0daf86fe518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.0\n",
            "-31.0\n",
            "21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(membrane_potential[1])"
      ],
      "metadata": {
        "id": "lCLfqQMHwWyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array_equal(output_spikes[0], spike_output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROMIq7hqEkYv",
        "outputId": "cdc25c8b-0094-459b-b714-1b072f63d316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array_equal(output_spikes[1], spike_output[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9G6qkox5CjX",
        "outputId": "7ad4b36d-f694-413a-8ff5-81f2e4e31164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array_equal(output_spikes[2], spike_output[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skYsCh3j_juD",
        "outputId": "e8d980d0-6b07-4284-98d7-35f64c285f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part3"
      ],
      "metadata": {
        "id": "IFmD_lyxS65c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format weights"
      ],
      "metadata": {
        "id": "UKCJ6mJITCb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the directory where you want to save the file\n",
        "save_dir = base_path + '/model_weights/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "qweights_file_path = os.path.join(save_dir, 'scnn_quant8b_weight_int.txt')\n",
        "\n",
        "# Save the weights to the text file in Google Drive\n",
        "with open(qweights_file_path, 'w') as f:\n",
        "  out_channels, in_channels, kernel_height, kernel_width = quant_weight_int.shape\n",
        "  f.write(f\"#{name}\\n\")\n",
        "  f.write(f\"#{quant_weight_int.shape}\\n\")\n",
        "  for out_ch in range(out_channels):\n",
        "      for in_ch in range(in_channels):\n",
        "          f.write(f\"Kernel {out_ch}-{in_ch}:\\n\")\n",
        "          kernel_weights = quant_weight_int[out_ch, in_ch]\n",
        "          for row in kernel_weights:\n",
        "              f.write(' '.join(map(str, row)) + '\\n')\n",
        "          f.write('\\n')\n",
        "\n",
        "print(f\"Weights saved to {qweights_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R_qCKz8S8m1",
        "outputId": "f61222a9-272e-4d33-ee6c-7aa643ff8edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights saved to /content/drive/My Drive/project_aug/v4/model_weights/scnn_quant8b_weight_int.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFR-pkvuJu4N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}